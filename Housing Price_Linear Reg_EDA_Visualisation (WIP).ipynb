{
  "cells": [
    {
      "metadata": {
        "_uuid": "cd92905c46e69fb8574a40d2c956bf52b8f7fa19"
      },
      "cell_type": "markdown",
      "source": "#Housing Price_Linear Regression_EDA_Visualisation\n---\n###Algorithms\nThis kernel attempts to apply following Python ML algorithms for the study: \n* Linear Regression without regularization\n* Linear Regression with Ridge regularization (L2 penalty)\n* Linear Regression with Lasso regularization (L1 penalty)\n* Linear Regression with ElasticNet regularization (L1 and L2 penalty)\n\n###Stages\nThe model has been built under following stages:\n1. Data Import and Premilinary Check\n2. Data Exploration and Visualisation \n3. Feature Engineering\n4. Build and Run\n5. Validate\n6. Model Comparison "
    },
    {
      "metadata": {
        "_uuid": "54db7e19bf58d54f35e23c96c1d283b279cc1745"
      },
      "cell_type": "markdown",
      "source": "##Stage 1: Data import and Premilinary Check\n\nThis stage helps in getting the idea of what the data comprises of - the size, the data type, missing values, the parameters/features i.e. data columns etc."
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Imports\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom scipy.stats import skew\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Definitions\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# load the dataset\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# check a few sample data points\ntrain.head()\ntrain.sample(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cfd4a27cddc1131c8a29e145717a00654daa39df"
      },
      "cell_type": "code",
      "source": "# get the dataset shape\nprint(\"Train data set shape: \", train.shape)\nprint(\"Test data set shape: \", test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f88d12a915adb7c0f1ed862c0af9beadb6d3db2"
      },
      "cell_type": "code",
      "source": "# get the dataset parameters\nprint(\"Train data set columns: \", train.columns.values)\nprint(\"Test data set columns: \", test.columns.values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22a36e83911a12ea1501a6def064d91d3c626b61"
      },
      "cell_type": "code",
      "source": "# check the dataset parameter datatype details \ndata_train.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3f4b2653a6c27656741bdabbe07a77e5a6536fc"
      },
      "cell_type": "code",
      "source": "# check the dataset parameter statistics detail \ndata_train.describe(include=\"all\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "415ad0582ede9fba9a37779c3decbc54f1892b17"
      },
      "cell_type": "code",
      "source": "# check for missing values\n#data_train.isnull().sum()\n# Create table for missing data analysis\ndef draw_missing_data_table(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()/df.shape[0]*100).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data\nmissing_train = draw_missing_data_table(train)\nmissing_test = draw_missing_data_table(test)\nprint(missing_train)\nprint(missing_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f0bbb4ad02b970e0300323dde7b734bdba658404"
      },
      "cell_type": "code",
      "source": "#analyse Target parameter \"SalePrice\" for skewness\nprint(train['SalePrice'].describe())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "721f66dac06d750747b417a49593577cd0032269"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}